{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "from datetime import *\n",
    "from  math  import *\n",
    "import statsmodels.api as sm\n",
    "import numpy.linalg as la   #用来做线性代数运算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from WindPy import *\n",
    "# # import talib as ta\n",
    "# # from talib.abstract import *\n",
    "# # w.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先采用**2021年8月1号**的沪深300为选股的股票池，然后选用数据的时间为*2010年1月1日至2021年12月31日*的数据来建立模型，在这之前，必须去掉2010年之前未上市的股票，筛选过后共有171只股票。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes =list(w.wset(\"sectorconstituent\", \"date=2021-08-01;windcode=000300.SH\",usedf=True)[1].iloc[:,1])\n",
    "# date = '2010-01-01'\n",
    "# date = datetime.strptime(date,'%Y-%m-%d')\n",
    "# df = w.wss(','.join(codes), \"ipo_issuedate\",usedf=True)[1]\n",
    "# select_codes = df.loc[df['IPO_ISSUEDATE']<=date].index.tolist()\n",
    "# len(select_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #估值因子\n",
    "# def get_values_factor(dates,stocks):\n",
    "#     dict_df = OrderedDict()\n",
    "#     for i in range(len(dates)-1):\n",
    "#         date=dates[i]\n",
    "        \n",
    "#         #估值因子value_factor\n",
    "#         factors_codes= \"pe_ttm,pe_lyr,pb_lf,pb_lyr,pcf_ncf_ttm,pcf_ocf_ttm,ps_ttm,ps_lyr,val_mvtofcff\" \n",
    "#         factors_names=['EP_TTM','EP_LYR','BP_LF','BP_LYR','NCF_TTM','OCF_TTM','SP_TTM','SP_LYR','FCFP_LYR'] \n",
    "#         factors_value=w.wss(stocks,factors_codes,\"tradeDate=\"+date) \n",
    "#         factors_value=pd.DataFrame(factors_value.Data,index=factors_names,columns=factors_value.Codes).T\n",
    "#         factors_value=1/factors_value\n",
    "            \n",
    "#         #获取PEG=市盈率/净利润同比增长率*100 \n",
    "#         PE=np.array(w.wss(stocks, \"pe_ttm\",\"tradeDate=\"+date).Data[0]) #获取市盈率 \n",
    "#         profit=np.array(w.wss(stocks, \"fa_npgr_ttm\",\"tradeDate=\"+date).Data[0]) #净利润同期增长率*100\n",
    "#         factors_value['PEG_TTM']=PE/profit   \n",
    "        \n",
    "#         #获取企业价值倍数\n",
    "#         factors_value['EV/EBITDA']=w.wss(stocks, \"ev2_to_ebitda\",\"tradeDate=\"+date).Data[0]\n",
    "        \n",
    "#         #获取股息率\n",
    "#         factors_value['DYR']=w.wss(stocks, \"dividendyield2\",\"tradeDate=\"+date).Data[0]\n",
    "        \n",
    "#         dict_df[date]=factors_value\n",
    "#     factors_values=pd.concat(dict_df.values(),keys=dict_df.keys())\n",
    "#     return factors_values\n",
    "# #规模因子\n",
    "# def get_size_factor(dates,stocks):\n",
    "#     dict_df = OrderedDict()\n",
    "#     for i in range(len(dates)-1):\n",
    "#         date=dates[i]\n",
    "#         size_factors=w.wss(stocks, \"val_lnmv,val_lnfloatmv,val_lntotassets\",\"tradeDate=\"+date)\n",
    "#         factors_names=['LN_MV','LN_FLOAT_MV','LN_TOTAL_ASSETS']                       \n",
    "#         size_factors=pd.DataFrame(size_factors.Data,index=factors_names,columns=size_factors.Codes).T\n",
    "#         dict_df[date]=size_factors.iloc[:,:]\n",
    "#         #print(dict_df.values())\n",
    "#         #print(dict_df.keys())\n",
    "#     size_factors=pd.concat(dict_df.values(),keys=dict_df.keys())\n",
    "#     return size_factors\n",
    "\n",
    "# #杠杆因子\n",
    "# def get_leverage_factors(dates,stocks,factors_codes,factors_names):\n",
    "#     dict_df = OrderedDict()\n",
    "#     for i in range(len(dates)-1):\n",
    "#         date=dates[i]\n",
    "#         leverage_factors=w.wss(stocks,factors_codes,\"tradeDate=\"+date)\n",
    "#         leverage_factors=pd.DataFrame(leverage_factors.Data,index=factors_names,columns=leverage_factors.Codes).T\n",
    "#         dict_df[date]=leverage_factors\n",
    "#     leverage_factors=pd.concat(dict_df.values(),keys=dict_df.keys())\n",
    "#     return leverage_factors\n",
    "# #技术因子\n",
    "# def get_Technical_factors(dates,stocks):\n",
    "#     dict_df = OrderedDict()\n",
    "#     for i in range(len(dates)-1):\n",
    "#         date=dates[i]\n",
    "#         factors_codes=\"tech_rvi,tech_rstr12,tech_cyf,tech_cry,tech_cr20\"\n",
    "#         factors_names=['RVI','RSTR12','CYF','CRY','CR20']\n",
    "#         Technical_factors=w.wss(stocks,factors_codes,\"tradeDate=\"+date)\n",
    "#         Technical_factors=pd.DataFrame(Technical_factors.Data,index=factors_names,columns=Technical_factors.Codes).T\n",
    "#          #获取RSI指标\n",
    "#         Technical_factors['RSI']=w.wss(stocks, \"RSI\",\"tradeDate=\"+date+\";RSI_N=6;priceAdj=F;cycle=D\").Data[0] \n",
    "#         #获取DEA异同平均数指标\n",
    "#         Technical_factors['DEA']=w.wss(stocks, \"MACD\",\"tradeDate=\"+date+\";MACD_L=26;MACD_S=12;MACD_N=9;MACD_IO=2;priceAdj=F;cycle=D\").Data[0]\n",
    "#         #获取MACD指标\n",
    "#         Technical_factors['MACD']=w.wss(stocks, \"MACD\",\"tradeDate=\"+date+\";MACD_L=26;MACD_S=12;MACD_N=9;MACD_IO=3;priceAdj=F;cycle=D\").Data[0]\n",
    "#         #获取K\\D\\J\n",
    "#         Technical_factors['K']=w.wss(stocks, \"KDJ\",\"tradeDate=\"+date+\";KDJ_N=9;KDJ_M1=3;KDJ_M2=3;KDJ_IO=1;priceAdj=F;cycle=D\").Data[0]\n",
    "#         Technical_factors['D']=w.wss(stocks, \"KDJ\",\"tradeDate=\"+date+\";KDJ_N=9;KDJ_M1=3;KDJ_M2=3;KDJ_IO=2;priceAdj=F;cycle=D\").Data[0]\n",
    "#         Technical_factors['J']=w.wss(stocks, \"KDJ\",\"tradeDate=\"+date+\";KDJ_N=9;KDJ_M1=3;KDJ_M2=3;KDJ_IO=3;priceAdj=F;cycle=D\").Data[0]\n",
    "        \n",
    "#         dict_df[date]=Technical_factors\n",
    "#     Liquidation_factors=pd.concat(dict_df.values(),keys=dict_df.keys())\n",
    "#     return Liquidation_factors\n",
    "# #动量因子\n",
    "# def get_Momentum_factors(dates,stocks):\n",
    "#     dict_df=OrderedDict()\n",
    "#     for i in range(len(dates)-1):\n",
    "#         date=dates[i]\n",
    "#         factors_codes=\"tech_revs5,tech_revs10,tech_revs60,tech_revs120,tech_revs250,tech_revs750,tech_revs1mmax,tech_lnhighlow20d\"\n",
    "#         factors_names=['REV_5D','REV_10D','REV_3M','REV_6M','REV_1Y','REV_3Y','REV_LAST1M_MAX','LN_HIGH-LOW']\n",
    "#         Momentum_factors=w.wss(stocks,factors_codes,\"tradeDate=\"+date)\n",
    "#         Momentum_factors=pd.DataFrame(Momentum_factors.Data,index=factors_names,columns=Momentum_factors.Codes).T\n",
    "#         dict_df[date]=Momentum_factors\n",
    "#     Momentum_factors=pd.concat(dict_df.values(),keys=dict_df.keys())\n",
    "#     return Momentum_factors\n",
    "\n",
    "# #获取成长因子\n",
    "# def get_growth_factors(dates,stocks):\n",
    "#     dict_df = OrderedDict()\n",
    "#     for i in range(len(dates)-1):\n",
    "#         date=dates[i]\n",
    "#         factors_codes= \"fa_orgr_ttm,fa_nagr,fa_gpmgr_ttm,fa_npgr_ttm,fa_tagr,fa_ncgr_ttm,fa_cfigr_ttm,fa_cffgr_ttm,fa_cfogr_ttm,fa_oigr_ttm\" \n",
    "#         factors_names=['sales_gr_TTM','net_asset_gr_TTM','gross_margin_gr_TTM','net_profit_gr_TTM','total_asset_gr_TTM','net_cash_flow_gr_TTM','invest_cash_flow_gr_TTM','finance_cash_folw_gr_TTM','operate_cash_flow_gr_TTM','operete_profit_gr_TTM']\n",
    "#         growth_factors=w.wss(stocks,factors_codes,\"tradeDate=\"+date)\n",
    "#         growth_factors=pd.DataFrame(growth_factors.Data,index=factors_names,columns=growth_factors.Codes).T\n",
    "#         #growth_factors['eps_growth_TTM']=w.wss(A_stocks, \"yoyeps_basic\",\"rptDate=\"+date+\";N=1\").Data[0]  #基本每股收益同比增长率\n",
    "#         #growth_factors['roe_growth_TTM']=w.wss(A_stocks, \"growth_roe\",\"rptDate=\"+date+\";N=1\").Data[0]  #净资产收益率N年同比增长率\n",
    "#         dict_df[date]=growth_factors\n",
    "#         growth_factors=pd.concat(dict_df.values(),keys=dict_df.keys())\n",
    "#     return growth_factors\n",
    "# #市值因子\n",
    "# def get_assisted_factors(dates,stocks):   \n",
    "#     dict_df = OrderedDict()\n",
    "#     for i in range(len(dates)-1):\n",
    "#         date=dates[i]\n",
    "#         assisted_factors=w.wss(stocks, \"industry_sw,mkt_cap_ashare\",\"tradeDate=\"+date+';industryType=1;unit=1')\n",
    "#         factors_names=['INDUSTRY_SW','CAP']                       \n",
    "#         assisted_factors=pd.DataFrame(assisted_factors.Data,index=factors_names,columns=assisted_factors.Codes).T\n",
    "#         dict_df[date]=assisted_factors\n",
    "#     assisted_factors=pd.concat(dict_df.values(),keys=dict_df.keys())\n",
    "#     return assisted_factors\n",
    "# #获取每月交易日期序列\n",
    "# def get_trade_date(start_date, end_date, period='M'):\n",
    "#     data = w.tdays(start_date, end_date, period=period) #获取每月最后一个交易日\n",
    "#     trade_dates = data.Data[0]\n",
    "#     trade_dates = [dt.strftime(\"%Y-%m-%d\") for dt in trade_dates]\n",
    "#     return trade_dates\n",
    "# def get_feature_names(data):  #该函数用于获取数据集中需测试的因子名\n",
    "#     columns = data.columns.tolist()\n",
    "#     fea_names = [i for i in columns if i not in [\"INDUSTRY_SW\",'CAP'] ]\n",
    "#     return fea_names\n",
    "# def extreme_process_MAD(Data):\n",
    "#     feature_names = get_feature_names(Data)\n",
    "#     median=Data[feature_names].median(axis=0)  #获取中位数\n",
    "#     MAD=abs(Data[feature_names].sub(median,axis=1)).median(axis=0)\n",
    "#     for j in range(len(MAD)):\n",
    "#         for i in range(Data.shape[0]):\n",
    "#             if np.isnan(Data.iloc[i,j]) == False:\n",
    "#                 if Data.iloc[i,j] <= median[j]-5*1.4826*MAD[j]:\n",
    "#                     Data.iloc[i,j] = median[j]-5*1.4826*MAD[j]\n",
    "#                 if Data.iloc[i,j] >= median[j]+5*1.4826*MAD[j]:\n",
    "#                     Data.iloc[i,j] = median[j]+5*1.4826*MAD[j]\n",
    "                    \n",
    "#     return Data\n",
    "# def fill_missing_value(Data):\n",
    "#     feature_names = get_feature_names(Data)\n",
    "#     for j in range(len(feature_names)):\n",
    "#         industry_fill_value = Data[feature_names[j]].groupby(Data['INDUSTRY_SW']).mean()\n",
    "#         #print(j,list(industry_fill_value))\n",
    "#         for i in range(Data.shape[0]):\n",
    "#             #if i < 3:\n",
    "#                 #print(Data.iloc[i,:]['INDUSTRY_SW'])\n",
    "#             if np.isnan(Data.iloc[i,j]):\n",
    "#                 #print(industry_fill_value[Data.iloc[i,-2]])\n",
    "#                 Data.iloc[i,j] = industry_fill_value[Data.iloc[i,-2]]\n",
    "#     return Data\n",
    "# #市值中性化\n",
    "# def data_scale_CAP(data):\n",
    "#     feature_names = get_feature_names(data)\n",
    "#     data_=data.copy()\n",
    "#     cap_weight = data_[\"CAP\"]/ data_[\"CAP\"].sum()\n",
    "#     for name in feature_names:\n",
    "#         avg=(data_[name]*cap_weight).sum()\n",
    "#         data_[name]=(data_[name]-avg)/data_[name].std()\n",
    "#     return data_\n",
    "# #行业中性化\n",
    "# def data_scale_neutral(data):\n",
    "#     feature_names = get_feature_names(data)\n",
    "#     data_=data.copy()\n",
    "#     industrys=data['INDUSTRY_SW']  #获取所属申万一级行业代码\n",
    "#     data_med = pd.get_dummies(data,columns=['INDUSTRY_SW'],drop_first=True)\n",
    "#     n = len(data['INDUSTRY_SW'].unique())    #确定产生虚拟变量个数\n",
    "#     X = np.array(data_med[data_med.columns[-(n-1):]])  #行业虚拟变量作为为自变量\n",
    "#     for name in feature_names:\n",
    "#         y = np.array(data_[name])\n",
    "#         if la.matrix_rank(X.T.dot(X)) == (n-1): #当矩阵满秩时，估计回归参数\n",
    "#             beta_ols = la.inv(X.T.dot(X)).dot(X.T).dot(y)  \n",
    "#             residual = y - X.dot(beta_ols)      #计算残差，并将其作为剔除行业影响的因子值 \n",
    "#         else:\n",
    "#             residual = y   #如果逆不存在的话 则 用原值\n",
    "#         data_[name]=residual\n",
    "#     return data_\n",
    "# #因变量涨跌幅的获取以及处理\n",
    "# def get_pct(dates,stocks):\n",
    "#     dict_df = OrderedDict()\n",
    "#     for i in range(len(dates)-1):\n",
    "#         date=dates[i]\n",
    "#         h = \"tradeDate=\"+date+\";cycle=M\"\n",
    "#         factors_value=w.wss(stocks,\"pct_chg\",h,usedf=True)[1]\n",
    "#         dict_df[date]=factors_value\n",
    "#     d=pd.concat(dict_df.values(),keys=dict_df.keys())\n",
    "#     return d\n",
    "# def accuracy(data1,data2):\n",
    "#     n=0\n",
    "#     for i in range(len(data1)):\n",
    "#         if data1[i] == data2[i]:\n",
    "#             n+=1\n",
    "#     acc = n/len(data1)\n",
    "#     return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date='20150101'\n",
    "# end_date='20201231'\n",
    "# dates=get_trade_date(start_date, end_date, period='M')\n",
    "# values_factor=get_values_factor(dates,select_codes)\n",
    "# size_factor=get_size_factor(dates,select_codes)\n",
    "# factors_codes=\"fa_current,fa_quick,fa_blev,fa_debttoasset,fa_cfotocurliabs_ttm,fa_debttoequity\"\n",
    "# factors_names=['CUR','QR','BOOK_LEVEL','DEBT_TO_ASSETS','CASH_FLOW_LIABILITY','DEBT_TO_EQUITY']\n",
    "# leverage_factors = get_leverage_factors(dates,select_codes,factors_codes,factors_names)\n",
    "# Technical_factors = get_Technical_factors(dates,select_codes)\n",
    "# Momentum_factors = get_Momentum_factors(dates,select_codes)\n",
    "# assisted_factors = get_assisted_factors(dates,select_codes)\n",
    "# growth_factors=get_growth_factors(dates,select_codes)\n",
    "# Data= pd.concat([values_factor,growth_factors,leverage_factors,Momentum_factors,Technical_factors,assisted_factors],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data.to_csv('Newsvm_15_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start_date='20200701'\n",
    "# end_date='20211231'\n",
    "# dates=get_trade_date(start_date, end_date, period='M')\n",
    "# values_factor=get_values_factor(dates,select_codes)\n",
    "# size_factor=get_size_factor(dates,select_codes)\n",
    "# factors_codes=\"fa_current,fa_quick,fa_blev,fa_debttoasset,fa_cfotocurliabs_ttm,fa_debttoequity\"\n",
    "# factors_names=['CUR','QR','BOOK_LEVEL','DEBT_TO_ASSETS','CASH_FLOW_LIABILITY','DEBT_TO_EQUITY']\n",
    "# leverage_factors = get_leverage_factors(dates,select_codes,factors_codes,factors_names)\n",
    "# Technical_factors = get_Technical_factors(dates,select_codes)\n",
    "# Momentum_factors = get_Momentum_factors(dates,select_codes)\n",
    "# assisted_factors = get_assisted_factors(dates,select_codes)\n",
    "# growth_factors=get_growth_factors(dates,select_codes)\n",
    "# Data1= pd.concat([values_factor,growth_factors,leverage_factors,Momentum_factors,Technical_factors,assisted_factors],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data1.to_csv('svm_20_21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date='20210101'\n",
    "# end_date='20211231'\n",
    "# dates=get_trade_date(start_date, end_date, period='M')\n",
    "# values_factor=get_values_factor(dates,select_codes)\n",
    "# size_factor=get_size_factor(dates,select_codes)\n",
    "# factors_codes=\"fa_current,fa_quick,fa_blev,fa_debttoasset,fa_cfotocurliabs_ttm,fa_debttoequity\"\n",
    "# factors_names=['CUR','QR','BOOK_LEVEL','DEBT_TO_ASSETS','CASH_FLOW_LIABILITY','DEBT_TO_EQUITY']\n",
    "# leverage_factors = get_leverage_factors(dates,select_codes,factors_codes,factors_names)\n",
    "# Technical_factors = get_Technical_factors(dates,select_codes)\n",
    "# Momentum_factors = get_Momentum_factors(dates,select_codes)\n",
    "# assisted_factors = get_assisted_factors(dates,select_codes)\n",
    "# growth_factors=get_growth_factors(dates,select_codes)\n",
    "# Data2= pd.concat([values_factor,growth_factors,leverage_factors,Momentum_factors,Technical_factors,assisted_factors],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data2.to_csv('svm_20_21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date='20100101'\n",
    "# end_date='20141231'\n",
    "# dates=get_trade_date(start_date, end_date, period='M')\n",
    "# values_factor=get_values_factor(dates,select_codes)\n",
    "# size_factor=get_size_factor(dates,select_codes)\n",
    "# factors_codes=\"fa_current,fa_quick,fa_blev,fa_debttoasset,fa_cfotocurliabs_ttm,fa_debttoequity\"\n",
    "# factors_names=['CUR','QR','BOOK_LEVEL','DEBT_TO_ASSETS','CASH_FLOW_LIABILITY','DEBT_TO_EQUITY']\n",
    "# leverage_factors = get_leverage_factors(dates,select_codes,factors_codes,factors_names)\n",
    "# Technical_factors = get_Technical_factors(dates,select_codes)\n",
    "# Momentum_factors = get_Momentum_factors(dates,select_codes)\n",
    "# assisted_factors = get_assisted_factors(dates,select_codes)\n",
    "# growth_factors=get_growth_factors(dates,select_codes)\n",
    "# Data3= pd.concat([values_factor,growth_factors,leverage_factors,Momentum_factors,Technical_factors,assisted_factors],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data3.to_csv('svm_10_14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
